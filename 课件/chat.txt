09:59:40	  imbafizz : 1
09:59:44	  BUG_MAN : 1
09:59:44	  hyalin : 1
10:00:21	  cath_kl : 诶现在好像又没有声音了？
10:00:25	  cath_kl : 有了
10:00:53	  KK : 1
10:01:38	  Zhuangboxu : 可以
10:01:39	  Feng : 可以
10:01:40	  张健 : 1
10:01:41	  46149090 : 1
10:01:42	  ww5365 : 1
10:01:43	  Feng : 1
10:01:43	  hyalin : 1
10:01:43	  贪心学院课程小助手 : 1
10:01:43	  KK : 1
10:01:43	  ANZ_DS : 1
10:01:43	  Zhuangboxu : 1
10:01:44	  567 : 1
10:01:44	  RayJue : 1
10:01:44	  Lee : 1
10:01:44	  有朝一日 : 1
10:01:45	  72352735 : 1
10:01:46	  王友全 : 1
10:01:47	  xiaomi : 1
10:01:48	  梁寓杰 : 1
10:01:49	  ANZ_DS : 1
10:01:49	  zhijian : 1
10:13:22	  1535508217 : 所以Pn代表不同的维度？
10:15:55	  滑车 : 点的坐标是连续的，而 seq2seq 的输出是离散的
10:16:23	  xiaomi : 也就是说用15个词的凸包把50个词给框起来？
10:17:29	  72352735 : 分类的类别数目不同
10:18:33	  hkc000 : 是oov问题么
10:26:22	  KK : <=  没有分数吗
10:26:53	  可立 : 遍历的是输入句子中存在的词？
10:27:15	  shisihuan24 : 这样科学?
10:27:22	  XUXIANGLAN : 好像是那个意思
10:27:38	  滑车 : decoder 如何更新参数？
10:29:02	  1535508217 : 所以output里面的词只能来自对应的input？
10:29:25	  Kelly : 所以就是主要做一些摘要类任务？
10:29:53	  Vince : 这样的应用是在什么场景？做autoencoder吗?
10:30:05	  可立 : 关键词提取？
10:30:19	  cath_kl : 没有弄懂为什么pointer network可以解决oov。。因为在全局50个点里选十几个，来做oov的表示？
10:30:33	  BUG_MAN : 取attention的max。decode是否需要处理重复的点
10:30:36	  1535508217 : 为什么不结合以前的seq2seq+attention的机制，如果vocabulary里面有，就用vocabulary里面的词，没有再用input里面的词，不就好了？
10:30:37	  晶品王 : 貌似是要和之前传统的结合起来，就可以有时候输出子集有时候输出nlu的
10:30:57	  晶品王 : nlg
10:31:07	  zhijian : 怎么结束呢？
10:31:20	  Will : 是不是还没讲完整个训练和预测流程？
10:31:52	  shisihuan24 : 这样根本不存在oov问题吧
10:31:53	  滑车 : 因为没有词表了，所以也不存在OOV了~~
10:32:08	  XUXIANGLAN : 对哦， 怎么结束啊
10:32:18	  shisihuan24 : 来啥训练啥 预测啥
10:32:38	  晶品王 : 在encode里面加一个end，如果预测到end就结束了
10:33:06	  shisihuan24 : 输入结束 预测就结束吧
10:33:06	  滑车 : 机智
10:33:25	  滑车 : attention 到 end 比较合理
10:33:26	  Vince : 这个只能做结果是前面输入的一部分子集的任务，不能做对话生成类的。
10:33:49	  有朝一日 : 感觉就是做文本抽取
10:34:07	  树第 : 能找k-max吗
10:34:19	  72352735 : 还有一种网络是copyNet
10:34:21	  cath_kl : 懂了
10:34:34	  72352735 : 可以即生成又复制
10:34:41	  hkc000 : att最大的输入Xt作为输出么
10:34:43	  72352735 : 既
10:35:33	  Will : 老师，你说的跟那个图不一样，那个图好像是decode的值还会回到encode
10:35:54	  xiaoliliu : 您说的这个是说新的数据来了是比之前的词库大，用过于的模型依旧希望生成结果吗？（针对于您说的15个和50个词表吗）
10:36:38	  KK : 既然能输入到encoder为什么还会出现OOV
10:37:05	  Will : 哦，明白了。是指向
10:37:36	  ww5365 : 这页ppt，刚才公式和图我也没对应起来
10:38:06	  ww5365 : ptr_net那个图
10:38:15	  liufeng : 不好意思 刚才没注意 跟之前讲的attention不一样的地方是？
10:38:25	  滑车 : 纠结 OOV 的同学，可以想一想原始的seq2seq的输入和输出分别是什么~
10:38:37	  62398743 : 这里的词汇表vocabulary是之前训练的所有的点吗
10:38:41	  滑车 : 输入是坐标，输出是 index
10:38:47	  72352735 : 原始seq2seq输出的词表是固定的
10:38:52	  46149090 : 预测阶段，输入输出都存在OOV的
10:39:39	  滑车 : 原始的seq2sq的问题就是必须事先指定最大 index （词表大小）
10:39:46	  Vince : 这个直接做max就可以了把？
10:39:58	  46149090 : unk不就时OOV吗
10:40:11	  于怼怼 : 人也经常oov，大家读文章是，遇见不认识的字时，就说明我们oov了
10:40:17	  滑车 : 我觉得引入 OOV 的概念，误导了大家~~
10:40:27	  滑车 : 这里就是 index 不够用的问题
10:40:42	  ww5365 : 嗯，明白了
10:40:56	  xiaomi : 还没讲完吧，怎么这么多问题。。。
10:41:04	  KK : 先继续吧
10:41:09	  sc_lj : 传统的oov词使用的是UNK替代的
10:41:18	  晶品王 : 你那50个词里面有10个词不在那10000个里，不就oov了，现在这种方法直接从50个里面取就可以了
10:41:49	  sc_lj : 现在是保留输入词，并用其扩大index。
10:41:52	  46149090 : 感觉就是解决预测UNK的时候怎么处理
10:42:07	  KK : 我也觉得
10:43:13	  滑车 : 输入（x,y） 输出 list(range(vocab_size))
10:43:30	  滑车 : 加 不了 unk token，加了也不解决问题
10:43:51	  滑车 : 。。。。
10:44:24	  滑车 : 呃，老师我错了。。。
10:44:52	  xiaomi : 把滑车打在公屏上哈哈哈哈
10:44:55	  Vince : 老师，那这个你从哪里来的？
10:45:04	  XUXIANGLAN : 对，怎么来的
10:45:04	  zhijian : oov 同学hh
10:45:06	  Vince : 应该不能生成你吧？
10:45:11	  shisihuan24 : 这样计算复杂度低?
10:45:19	  胡云聪 : 可能问题在滑车输入的embedding是啥
10:45:49	  62398743 : 老师，那这个你从哪里来的？
10:45:55	  hkc000 : 一开始有100个词表的数据集，那么训练seq的softmax就固定了100的大小，下一次有200的词表的数据集，就没办法生成多余的词了？？
10:46:00	  imbafizz : 这个是混合用的情况吧，在oov的时候采用pointnet
10:46:13	  46149090 : 是的
10:46:28	  滑车 : point-wise 的encoder是没有词表的，同学们
10:46:35	  cath_kl : 发了
10:46:48	  滑车 : pointer-network
10:46:55	  KK : born
10:47:04	  hyalin : 有同學開視訊了
10:56:56	  lyj : ...
10:56:57	  SimonChen : ？
10:57:00	  滑车 : 袁老师？？？？
10:57:01	  89939482 : ？？
10:57:02	  46149090 : 。。。。
10:57:03	  Vince : 啥情况?
10:57:30	  xiaomi : 人工智能从婴儿抓起
10:57:44	  晶品王 : 老师，我怎么觉得原文1-7的公式讲的是Sequence-to-sequence attentional model，还没有讲到Pointer-generator network
10:57:44	  南墙顾南墙 : 听课
10:57:51	  滑车 : 小朋友都在学 AI 了
10:57:54	  Born alone° : 袁老师，是好爸爸👨🏻
10:58:22	  xiaomi : 老师跟下一页的公式讲串了好像
10:58:57	  XUXIANGLAN : 听得有点晕。。
10:59:02	  cath_kl : 哪两个相加？
10:59:21	  hyalin : 全局詞表&source吧
10:59:22	  cath_kl : 原来language model得到的词向量 和point network根据这句句子encoder得到的 加起来？
10:59:29	  cath_kl : 哦好的
10:59:36	  Vince : 如果要用上vocab词表的分布，这OOV不还是会存在吗?
10:59:39	  46149090 : 应该是对应词概率相加吧
10:59:41	  滑船 : 如果distribution这样相加 然后source里的分布如果有oov的话，这样怎么直接加呀？
10:59:55	  BUG_MAN : 和原来的attention相加？
11:00:35	  lyj : 老师可以放大一点吗，字和图都有点模糊
11:01:36	  kin : 是的，放大一点吧
11:05:57	  1535508217 : P总 = 1吗？
11:07:16	  hyalin : 給樓上，是 最終每個詞的機率分佈
11:09:50	  滑车 : 加完总和大于一了呀？
11:11:08	  XUXIANGLAN : 所以Final Distribution的分布， 很可能会大于vocab的分布，是吗
11:11:21	  96801284 : bingo
11:12:12	  hyalin : 簡而言之就是詞表表示不好的用source裡的詞表示
11:12:25	  Will : 如果另外一边是zoo呢，不是阿根廷，会怎样
11:12:44	  滑车 : 对应相加
11:12:59	  KK : final distribution的大小是多少
11:13:13	  滑车 : LM 的词表大小
11:13:21	  XUXIANGLAN : 然后再softmax，找出概率最大的那个，对吗
11:13:43	  KK : 那些生僻词在最后怎么表示
11:13:46	  晶品王 : 这种是不是减缓OOV，并没有消除？
11:13:53	  胡云聪 : 不用softmax吧，加了这个权重应该归一化了
11:13:53	  szb : 明白了
11:13:54	  于怼怼 : p_vocab和p_source这俩分布的包含的元素不一样啊，咋相加？求并集？两个分布都含的元素相加？
11:14:02	  xiaomi : 老师，第9页公式（9）怎么相加？加号两边的向量维度都不同
11:14:03	  46149090 : 不一定消除了
11:14:13	  hkc000 : 2个概率分布中有相同词的就相加么
11:14:53	  滑船 : 那如果Attention Distribution中有OOV的概率，然后把Attention Distribution和LM的Distribution相加，相当于最后的Final Distribution维度可能会大于LM产生的Distribution的维度？
11:14:55	  lyj : 两个分布相加之后，怎么保证final分布的和还是1呢？
11:14:56	  XUXIANGLAN : 明白 
11:15:47	  limingkailmk : 应该会增加维度
11:16:06	  46149090 : input词不在词表里面就增加维度了
11:16:18	  胡云聪 : 是不是比如词典1w个词，但是还要预留出比如50个位置给输入里的oov，这样才能找到input？
11:16:26	  滑船 : 好的
11:18:19	  72352735 : 0.5*0.5+0.5*0 吧
11:18:36	  Vince : 有一个问题，这个2.0的embedding从哪来?
11:18:37	  KK : encoder每个词的embedding怎么表示
11:18:51	  BUG_MAN : 讲的很清晰
11:18:56	  滑车 : 这咋训练呢？？
11:19:14	  Vince : 如果都看成oov的话，这样所有不在词表的embedding向量都是一样的啊。
11:19:18	  xiaoliliu : 用one-hot?
11:19:18	  Will : 就是两个词表相加
11:19:20	  Vince : 他怎么知道是2,0
11:19:23	  胡云聪 : 我记得模型里输入还有个oov_len，应该是根据oov长度在新建一个全零向量表征oov，在concatenate在一起吧
11:19:42	  晶品王 : Pgen是学出来的
11:19:48	  胡云聪 : 和pvocabconcatenate
11:20:19	  Vince : 能拆开拼接，就能生成。不能算oov
11:21:51	  1535508217 : Pgen是个distribution吗？
11:22:08	  lyj : Pgen是一个概率
11:22:13	  lyj : 概率值
11:22:16	  滑车 : pgen是一个值，相当于 gate
11:22:25	  1535508217 : 怎么算出来的？
11:22:28	  72352735 : Pgen的值怎么确定啊？
11:22:33	  滑车 : 公式 8
11:22:38	  46149090 : 公式
11:22:39	  72352735 : 噢噢噢噢
11:22:45	  lyj : Pgen是全局只有一个还是每个时间步都有自己的Pgen?
11:22:48	  xiaomi : 2-0怎么embedding
11:22:53	  Vince : 老师，有一个问题，如果都是OOV，如果有多个OOV怎么办?
11:22:53	  46149090 : 每个步
11:22:57	  limingkailmk : 会增加维度吗，刚才断网了
11:22:57	  XUXIANGLAN : 2：0的embedding是怎么来的呢
11:23:03	  Will : point network 这边是出最大值还是所有值的概率？
11:23:21	  胡云聪 : 应该是在pvocab后面增加oov_len个维度
11:23:24	  滑车 : 增加维度咋训练呀？
11:23:30	  Vince : 老师，有一个问题，如果都是OOV，如果有多个OOV怎么办?
11:24:02	  xiaomi : 训练也是NLL，一样的吧
11:24:17	  46149090 : 维度增加没有参数吧
11:24:49	  晶品王 : OOV也可以分的吧，项目二里面有
11:25:14	  ml : 后面两个paper 发我们一下 
11:25:17	  滑车 : 嗯，懂了，增加的维度没参数~
11:25:38	  hkc000 : 记录source的index就行了吧
11:25:41	  xiaomi : 多个OOV不是都表示成UNK么,那怎么区分
11:25:57	  Will : point network 这边前面说是出最大值，这里还是最大值吗，还是所有值的概率？
11:26:12	  Vince : 不区别的话，那么decoder学到的是这个位置关系。
11:26:15	  BUG_MAN : 记录下来就可以了
11:26:28	  Vince : 2.0换成别的任何一个OOV都会认识
11:26:50	  五九 : 这个分布只考虑词频吧，对没什么含义的虚词可能更重，对停用词依赖应该比较大吧？
11:26:52	  xiaomi : 哦哦，记录位置
11:26:54	  96801284 : 其实是在inference的时候选择输出词的时候能够直接输出input里有的词
11:26:55	  Will : 明白了
11:27:13	  晶品王 : 多个OOV的看项目二utils.py的source2ids方法，感觉就是讲的这里
11:27:17	  hyalin : 老師累了
11:27:24	  Vince : 老师，不区别的话，那么decoder学到的是这个位置关系。2.0换成别的任何一个OOV都会认识。这个很bug
11:27:39	  SimonChen : 针对输入的概率分布到底是根据attention来的还是pointer network来的？
11:27:41	  胡云聪 : 对的source2id没有直接把oov全部替换为unk，而是进行了暂时的记录
11:27:42	  Vince : 多个oov都是oov
11:27:51	  晶品王 : A list of word ids (integers); OOVs are represented by their temporary
        source OOV number. If the vocabulary size is 50k and the source has 3
        OOVs tokens, then these temporary OOV numbers will be 50000, 50001,
        50002.
11:27:56	  Vince : 都是同一个oov的embedding
11:28:02	  sc_lj : 怎么构建这个oov呢？是对当前input句子构建oov的index，还是当前batch的所有句子oov的index？
11:28:02	  SimonChen : 就是蓝色那一块
11:28:36	  imbafizz : source2id是暂时存放？
11:28:54	  晶品王 : 是啊，看上面那段英文
11:29:36	  ww5365 : 公式8中的st，不应该是st-1吗？我理解的问题?
11:29:37	  liufeng : 就是临时给他一个编号
11:29:39	  胡云聪 : 就比如你原来有1w个词，oov就是10001和10002，然后在输入网络的时候你把1w以上的输入为unk，但是point的时候你使用10001和10002
11:29:57	  Vince : 在推理中如果2:0，换成任何一个不在词表中的，都会被认识。
11:29:57	  limingkailmk : 也就说输入中所有的oov embedding 都一样
11:30:02	  limingkailmk : ？

11:30:08	  46149090 : 可以一样
11:30:08	  晶品王 : 就是项目二里面需要做的 TODO: module 1 task 3
11:30:10	  imbafizz : 一样的
11:30:13	  liufeng : 这句话训练完 这个编号就释放了，后面可以用相同的编号代替不同的词
11:30:17	  xiaoliliu : 多个OOV的embedding虽然是一样的，vocab的分布是一样的，但是source的distribution是不同的。所以可以区分
11:30:25	  Vince : 例如2:0换成"DAKLJDL"一样会被认识。
11:30:33	  BUG_MAN : 如何有多个unk1、unk2...就不一样了
11:30:38	  BUG_MAN : 如果
11:30:47	  xiaoliliu : 看一下公式(4)和（9）
11:30:53	  liufeng : embedding不一样 临时的
11:31:15	  46149090 : 有点小难度
11:31:24	  SimonChen : 老师，课件能否提前一天发出来？
11:31:43	  Jessie_Zhu : 所以这里unk主要是依赖上下文来学习么？
11:31:46	  Vince : 老师，这个结构下，如果2:0换成"DAKLJDL"一样会被认识。
11:32:08	  46149090 : 这周没有吧
11:32:24	  xiaoliliu : 嗯，这周讲项目二的代码
11:32:49	  五九 : 这个分布只考虑词频吧，对没什么含义的虚词可能更对停用词依赖应该比较大吧？
11:32:55	  晶品王 : 这周估计是讲传统的
11:32:56	  liufeng : 嗯 应该是依赖上下文 不同句子出现相同的oov词 应该是不同的embedding
11:34:50	  limingkailmk : switch
11:45:01	  晶品王 : 这感觉和之前那个很像啊
11:45:11	  XUXIANGLAN : 嗯
11:45:24	  晶品王 : 这就可以发一篇不一样的论文了啊。。。
11:45:47	  lyj : detail的信息是体现在background knowledge吗？
11:45:48	  胡云聪 : 如果只有单纯的point network，那embedding是预训练过的吗？
11:46:25	  1535508217 : partial summary是生成的吗？
11:46:43	  35494826 : bk是有序的吗？还是单词的集合？
11:47:10	  1535508217 : Bk其实就是商品属性
11:47:29	  kin : 哈哈
11:47:36	  1535508217 : 比如说，营销文本的生成
11:47:45	  lyj : BK就是商品detail信息的体现吗？
11:47:46	  kin : 阿里这篇发到什么级别啊
11:48:03	  xiaoliliu : 怎么去评估模型的效果呢？对比之前和现在的
11:48:13	  1535508217 : 这篇文章有code吗？
11:48:18	  hkc000 : 大家对发论文蠢蠢欲动啊
12:09:08	  limingkailmk : 触发条件
12:09:08	  sweet_smile : 没
12:09:10	  lyj : Ts是啥？
12:09:12	  滑车 : 拼接维度就不一致了？
12:09:23	  lyj : 公式9里面
12:09:34	  1535508217 : CopyNet的应用例子？
12:09:48	  晶品王 : 上面那行
12:09:50	  xiaomi :  累加符号
12:09:52	  lyj : 公式就的第一行
12:09:53	  胡云聪 : 求和符号上
12:09:54	  BUG_MAN : 求和那里
12:09:55	  滑车 : time step
12:09:57	  有朝一日 :  求和符号上那个
12:09:57	  晶品王 : 累加的地方
12:09:59	  hyalin : suumation
12:10:16	  滑车 : total step
12:10:32	  lyj : 了解了，谢谢
12:10:59	  1535508217 : 对应那篇文章？
12:11:23	  滑车 : copynet 的拼接，维度不一致如何处理？
12:11:51	  滑车 : 下面 tony 那里的拼接
12:12:36	  滑车 : tony 是原文出现了才拼接
12:27:08	  lyj : alpha的作用可以再说一下吗~
12:27:10	  SimonChen : Ty是输入的长度？
12:27:15	  SimonChen : 还是目标的长度？
12:27:22	  46149090 : alpha可学习的？？
12:28:45	  胡云聪 : alpha越小越鼓励小句子吧
12:29:08	  35494826 : 哪篇文章里的呢
12:36:25	  limingkailmk : attetion score不是会动态变化吗，怎么会我一直很大呢
12:36:46	  滑车 : 一切皆有可能
12:37:18	  limingkailmk : 训练有监督学习，感觉这样概率很小
12:42:49	  滑车 : attenion 没有直接的监督
12:49:53	  limingkailmk : coverge norm 是不是隐状态输出目标词后，在对attention socre 约束一下输入到下一步
12:50:25	  xiaoliliu : 老师，求和j=1到|Y|是不是该在min外面呢？（coverage normalization）
12:51:43	  胡云聪 : 那句子越长这个值不是越大吗
12:52:46	  limingkailmk : 没明白为啥能够解决over_translation问题
12:57:55	  滑车 : 这个逻辑是这样的，发现模型会出现 IIIIIIII，然后猜测，可能是 attention 的问题，想出了这个方法，发现可以缓解问题~
13:02:59	  limingkailmk : 好的，谢谢老师，谢谢滑车
13:04:11	  滑车 : tony 拼接 那里还是没太明白，能再解释一下吗？
13:05:53	  滑车 : 触发才会拼接，不触发就没有拼接？
13:05:59	  滑车 : 维度不会不一致吗？
13:06:23	  滑车 : 明白了~谢谢老师~
13:06:27	  胡云聪 : 老师这个coverage norm应该还是在输入输出序列长度相似的情况下吧，要不这个min( ,1.0)的阈值应该需要调节吧
13:06:31	  BUG_MAN : 就是一个判断计算
13:06:40	  ml : 2点就有 
13:06:42	  BUG_MAN : 谢谢老师
13:06:47	  南墙顾南墙 : 谢谢老师
13:06:48	  ml : 谢谢老师 
13:06:53	  SimonChen : 谢谢老师~
13:06:54	  愚蠢的人类 : 感谢老师
13:06:57	  SimonChen : 要
13:06:59	  南墙顾南墙 : 要
13:06:59	  46149090 : 要的
13:06:59	  hyalin : 謝謝老師!!
13:06:59	  imbafizz : 要
13:07:03	  limingkailmk : 要
13:07:07	  南墙顾南墙 : 谢谢老师
13:07:08	  xiaoliliu : 老师辛苦啦~ 谢谢老师~
13:07:13	  billyzhang24kobe : 谢谢老师
13:07:27	  hyalin : 講什麼主題呢
13:07:28	  BeyondRiver : 好！
13:07:30	  于怼怼 : 谢谢老师
13:07:30	  BeyondRiver : 谢谢老师
13:07:35	  BeyondRiver : 明天两点么
13:07:38	  Ben : onsltm
13:07:41	  Ben : onlstm
13:07:46	  ml : 这周是不是 要休息一次 
13:07:48	  hyalin : 哦哦期待!
13:07:54	  ml : 明天没有其他课  
13:08:04	  滑车 : 谢谢老师！~
13:08:05	  hyalin : 謝謝老師
13:08:05	  韩晓东 : 谢谢老师
13:08:07	  ww5365 : 谢谢老师
13:08:26	  zjbit : 谢谢老师
13:08:46	  五九 : 谢谢老师
13:11:09	  Swiftcheung : 谢谢老师
